---
layout: default
title: Research Areas
---

<div class="blurb">
	<h1>Is task-irrelavent information discarded in neural networks?</h1>
	<p>The traditional view of abstraction in psychology suggests that as information for one task is further processed, other information is progressively
  discarded. In line with this, research using deep neural networks has shown features became increasingly specialized for the trained task in the later 
  layers of the network when continuing to train over the rest of the neural network.
   However, more recent neuroimaging evidence in face and object perception have suggested this may not be the case. 
  For example, face identity and facial expression information have been founded to be encoded in common brain regions. One question to now consider
  then is why information for an irrelevant task would need to be discarded? If one can prove that in a computational system information for one task 
  (e.g., face identity recognition) does not needed to be discarded when processing facial expression, this could be a potential explanation for why
		we find information for both tasks in shared neural regions.</p>
    
   <p>Representations optimized for expression recognition may contribute to identity recognition and vice versa. If recognition of 
  face identity and facial expression are mutually beneficial, training
    an algorithm to recognize face identity might lead to the spontaneous formation of representations that encode facial expression information and, 
    likewise, training a separate algorithm to recognize facial expression might lead to the spontaneous emergence of representations that encode face 
    identity information. If this phenomenon occurs because disentangling identity from expression helps to also achieve the reverse, 
    then integrated representations would not arise because recognition of identity and expression rely on common features. On the contrary, features 
    important for the recognition of face identity and features important for the recognition of facial expression should become increasingly disentangled 
	   and orthogonal along the processing stream.</p>
    
	<p>DCNNs trained to label one property (i.e., expression), the readout performance of 
    the non-trained property (i.e., identity) was not just preserved, but improved, from layer to layer. The relationship between 
    features encoding information that distinguish between identities and expressions across different layers of the DCNNs. We demonstrated that 
    identity-discriminating features and expression-discriminating features became increasingly orthogonal over the network layers. 
</p>
	<div class="image">
        <img src="/Research/figure4.png", width="750" height="auto" class="center">
      	</div>
	
</div><!-- /.blurb -->
